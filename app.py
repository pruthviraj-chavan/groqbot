import os
import logging
from datetime import datetime, timedelta
from flask import Flask, request, Response, jsonify
from twilio.twiml.voice_response import VoiceResponse, Gather
from groq import Groq
import re
import json
import threading
import time

app = Flask(__name__)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API credentials
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
TWILIO_ACCOUNT_SID = os.environ.get("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.environ.get("TWILIO_AUTH_TOKEN")

# Initialize Groq client
try:
    client = Groq(api_key=GROQ_API_KEY)
    logger.info("‚úÖ Groq client initialized successfully")
except Exception as e:
    logger.error(f"‚ùå Error initializing Groq client: {e}")
    client = None

# Enhanced conversation storage with interruption tracking
conversation_contexts = {}
call_states = {}
active_speech_sessions = {}  # Track active speech processing

class CallState:
    def __init__(self, caller_id):
        self.caller_id = caller_id
        self.start_time = datetime.now()
        self.interaction_count = 0
        self.last_activity = datetime.now()
        self.user_sentiment = "neutral"
        self.conversation_topic = None
        self.interruption_count = 0
        self.silence_count = 0
        self.is_speaking = False
        self.last_speech_time = None
        self.speech_buffer = []
        self.rapid_interruptions = 0

def get_enhanced_conversation_context(caller_id):
    """Get or create enhanced conversation context for a caller"""
    if caller_id not in conversation_contexts:
        conversation_contexts[caller_id] = [
            {
                "role": "system", 
                "content": """‡§Ü‡§™ ‡§è‡§ï ‡§§‡•á‡§ú‡§º ‡§î‡§∞ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§π‡§ø‡§Ç‡§¶‡•Ä AI ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç‡•§ ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Ç:

1. ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ú‡§µ‡§æ‡§¨: ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•á ‡§¨‡•ã‡§≤‡§§‡•á ‡§π‡•Ä ‡§∏‡§Æ‡§ù ‡§ú‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
2. ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§â‡§§‡•ç‡§§‡§∞: 25-35 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§ü‡•Ä‡§ï ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
3. ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï: ‡§∏‡•Ä‡§ß‡•á ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á ‡§™‡§∞ ‡§Ü‡§è‡§Ç, ‡§≤‡§Ç‡§¨‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§® ‡§¨‡§æ‡§Ç‡§ß‡•á‡§Ç
4. ‡§¶‡•ã‡§∏‡•ç‡§§‡§æ‡§®‡§æ: ‡§∏‡§π‡§ú ‡§î‡§∞ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡§∞‡•á‡§Ç
5. ‡§¨‡§æ‡§ß‡§æ ‡§∏‡§π‡§®‡§∂‡•Ä‡§≤: ‡§Ö‡§ó‡§∞ ‡§ï‡•ã‡§à ‡§¨‡•Ä‡§ö ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á ‡§§‡•ã ‡§∞‡•Å‡§ï‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•Å‡§®‡•á‡§Ç
6. ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ: ‡§¶‡•á‡§∞ ‡§® ‡§ï‡§∞‡•á‡§Ç, ‡§ù‡§ü ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç

‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§∂‡•à‡§≤‡•Ä:
- ‡§∏‡§µ‡§æ‡§≤: "‡§Æ‡•Å‡§ù‡•á ‡§®‡•å‡§ï‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤ ‡§∞‡§π‡•Ä"
- ‡§ú‡§µ‡§æ‡§¨: "‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ‡•§ ‡§Ö‡§™‡§®‡•Ä ‡§∏‡•ç‡§ï‡§ø‡§≤‡•ç‡§∏ ‡§¨‡§¢‡§º‡§æ‡§è‡§Ç, LinkedIn ‡§™‡§∞ ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤ ‡§¨‡§®‡§æ‡§è‡§Ç, ‡§î‡§∞ ‡§∞‡•ã‡§ú‡§º‡§æ‡§®‡§æ 10-15 ‡§ú‡•â‡§¨‡•ç‡§∏ apply ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§ï‡•å‡§® ‡§∏‡§æ ‡§´‡•Ä‡§≤‡•ç‡§° ‡§π‡•à ‡§Ü‡§™‡§ï‡§æ?"

‡§§‡•á‡§ú‡§º‡•Ä ‡§∏‡•á, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç‡•§"""
            }
        ]
        call_states[caller_id] = CallState(caller_id)
    return conversation_contexts[caller_id]

def analyze_user_sentiment(text):
    """Quick sentiment analysis"""
    positive_words = ['‡§ñ‡•Å‡§∂', '‡§Ö‡§ö‡•ç‡§õ‡§æ', '‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ', '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§†‡•Ä‡§ï', '‡§∏‡§π‡•Ä', 'great', 'good', 'thanks', 'ok']
    negative_words = ['‡§™‡§∞‡•á‡§∂‡§æ‡§®', '‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ', '‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ', '‡§¶‡•Å‡§ñ‡•Ä', '‡§®‡§π‡•Ä‡§Ç', '‡§ó‡§≤‡§§', 'problem', 'wrong', 'bad', 'no']
    
    text_lower = text.lower()
    positive_count = sum(1 for word in positive_words if word in text_lower)
    negative_count = sum(1 for word in negative_words if word in text_lower)
    
    if positive_count > negative_count:
        return "positive"
    elif negative_count > positive_count:
        return "negative"
    return "neutral"

def detect_interruption_intent(text):
    """Detect if user is trying to interrupt or change topic"""
    interruption_phrases = [
        '‡§∞‡•Å‡§ï‡•ã', '‡§∞‡•Å‡§ï‡§ø‡§è', 'stop', 'wait', '‡§≤‡•á‡§ï‡§ø‡§®', 'but', '‡§®‡§π‡•Ä‡§Ç ‡§®‡§π‡•Ä‡§Ç', 'no no',
        '‡§∏‡•Å‡§®‡§ø‡§è', 'actually', '‡§µ‡§æ‡§∏‡•ç‡§§‡§µ ‡§Æ‡•á‡§Ç', '‡§Ö‡§∞‡•á', '‡§Ö‡§ö‡•ç‡§õ‡§æ', 'okay but',
        '‡§è‡§ï ‡§Æ‡§ø‡§®‡§ü', 'minute', '‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¨‡§æ‡§§', 'another thing', '‡§™‡§π‡§≤‡•á', 'first'
    ]
    
    text_lower = text.lower().strip()
    return any(phrase in text_lower for phrase in interruption_phrases)

def generate_fast_response(prompt, caller_id):
    """Generate quick AI response optimized for interruptions"""
    try:
        if not GROQ_API_KEY or not client:
            return "‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§"
            
        if not prompt or len(prompt.strip()) < 2:
            return "‡§ú‡•Ä ‡§π‡§æ‡§Å, ‡§ï‡§π‡§ø‡§è?"
        
        # Quick interruption detection
        if detect_interruption_intent(prompt):
            return "‡§ú‡•Ä ‡§π‡§æ‡§Å, ‡§¨‡§§‡§æ‡§á‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?"
        
        # Update call state quickly
        call_state = call_states.get(caller_id)
        if call_state:
            call_state.interaction_count += 1
            call_state.last_activity = datetime.now()
            call_state.user_sentiment = analyze_user_sentiment(prompt)
        
        messages = get_enhanced_conversation_context(caller_id)
        
        # Simplified context for speed
        messages.append({"role": "user", "content": prompt})
        
        logger.info(f"Quick response for: {prompt[:50]}...")
        
        # Optimized Groq parameters for speed
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            max_tokens=80,  # Reduced for faster response
            temperature=0.7,
            top_p=0.9,
            stream=False
        )
        
        response_text = completion.choices[0].message.content.strip()
        messages.append({"role": "assistant", "content": response_text})
        
        # Aggressive memory management for speed
        if len(messages) > 15:  # Keep only recent conversation
            messages = messages[:1] + messages[-14:]
        
        logger.info(f"Fast response: {response_text}")
        return response_text
        
    except Exception as e:
        logger.error(f"Error in fast response: {e}")
        return "‡§π‡§æ‡§Å, ‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ‡•§ ‡§ï‡•ã‡§à ‡§î‡§∞ ‡§∏‡§µ‡§æ‡§≤?"

@app.route("/voice", methods=['POST'])
def voice():
    """Optimized voice handler for fast interruption response"""
    try:
        response = VoiceResponse()
        caller_id = request.form.get('From', 'unknown')
        
        logger.info(f"Fast call handler for: {caller_id}")
        
        # Quick, friendly welcome
        response.say(
            "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§ú‡•ã ‡§≠‡•Ä ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç, ‡§¨‡•á‡§ù‡§ø‡§ù‡§ï ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§", 
            voice="Polly.Aditi", 
            language="hi-IN"
        )
        
        # Optimized gather for interruptions
        gather = Gather(
            input="speech", 
            action="/process_voice", 
            method="POST", 
            language="hi-IN", 
            speech_timeout="auto",
            timeout=8,  # Shorter timeout for responsiveness
            action_on_empty_result=True,  # Handle empty results
            hints="‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ,‡§∏‡§µ‡§æ‡§≤,‡§Æ‡§¶‡§¶,‡§ï‡§æ‡§Æ,‡§™‡•à‡§∏‡§æ,‡§∞‡•Å‡§ï‡•ã,‡§≤‡•á‡§ï‡§ø‡§®,‡§Ö‡§ö‡•ç‡§õ‡§æ"
        )
        
        gather.say(
            "‡§ú‡•Ä ‡§¨‡•ã‡§≤‡§ø‡§è, ‡§Æ‡•à‡§Ç ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§", 
            voice="Polly.Aditi", 
            language="hi-IN"
        )
        response.append(gather)
        
        # Quick fallback
        response.say(
            "‡§ï‡•â‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", 
            voice="Polly.Aditi", 
            language="hi-IN"
        )
        
        return Response(str(response), content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in voice route: {e}")
        response = VoiceResponse()
        response.say("‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§", voice="Polly.Aditi", language="hi-IN")
        return Response(str(response), content_type='text/xml')

@app.route("/process_voice", methods=['POST'])
def process_voice():
    """Ultra-fast voice processing with interruption handling"""
    try:
        response = VoiceResponse()
        caller_id = request.form.get('From', 'unknown')
        
        speech_text = request.form.get("SpeechResult", "").strip()
        confidence = float(request.form.get("Confidence", "0"))
        
        logger.info(f"Processing: '{speech_text}' (Confidence: {confidence})")
        
        call_state = call_states.get(caller_id)
        
        # Handle empty or very low confidence speech quickly
        if confidence < 0.4 or not speech_text:
            if call_state:
                call_state.silence_count += 1
                
            if call_state and call_state.silence_count >= 3:
                response.say("‡§ï‡•ã‡§à ‡§¶‡§ø‡§ï‡•ç‡§ï‡§§ ‡§π‡•à? ‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Ç‡•§", voice="Polly.Aditi", language="hi-IN")
                response.hangup()
                return Response(str(response), content_type='text/xml')
            
            # Quick retry for unclear speech
            gather = Gather(
                input="speech", 
                action="/process_voice", 
                method="POST", 
                language="hi-IN", 
                speech_timeout=2,  # Very short timeout
                timeout=6,
                hints="‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§ú‡•Ä,‡§†‡•Ä‡§ï ‡§π‡•à,‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ"
            )
            gather.say("‡§ú‡•Ä, ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡•ã‡§≤‡§ø‡§è‡•§", voice="Polly.Aditi", language="hi-IN")
            response.append(gather)
            
            response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", voice="Polly.Aditi", language="hi-IN")
            return Response(str(response), content_type='text/xml')
        
        # Reset silence count
        if call_state:
            call_state.silence_count = 0
        
        # Quick goodbye detection
        end_phrases = ['‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§¨‡§æ‡§Ø', 'bye', '‡§ñ‡§§‡•ç‡§Æ', '‡§¨‡§∏', '‡§π‡•ã ‡§ó‡§Ø‡§æ', '‡§∞‡§ñ‡§§‡§æ ‡§π‡•Ç‡§Ç']
        if any(phrase in speech_text.lower() for phrase in end_phrases):
            response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§ï‡•á‡•§ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á!", voice="Polly.Aditi", language="hi-IN")
            response.hangup()
            
            # Quick cleanup
            if caller_id in conversation_contexts:
                del conversation_contexts[caller_id]
            if caller_id in call_states:
                del call_states[caller_id]
                
            return Response(str(response), content_type='text/xml')
        
        # Generate super-fast response
        ai_response = generate_fast_response(speech_text, caller_id)
        
        # Speak response immediately - no pauses
        response.say(ai_response, voice="Polly.Aditi", language="hi-IN")
        
        # Immediate next input gathering with shorter timeout
        gather = Gather(
            input="speech", 
            action="/process_voice", 
            method="POST", 
            language="hi-IN", 
            speech_timeout=1,  # Very quick speech detection
            timeout=8,  # Short overall timeout
            action_on_empty_result=True,
            hints="‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§î‡§∞,‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ,‡§†‡•Ä‡§ï ‡§π‡•à,‡§≤‡•á‡§ï‡§ø‡§®,‡§∞‡•Å‡§ï‡•ã,‡§Ö‡§ö‡•ç‡§õ‡§æ,‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶"
        )
        
        # Quick continuation prompt
        quick_prompts = ["‡§î‡§∞?", "‡§ú‡•Ä ‡§π‡§æ‡§Å?", "‡§ï‡•Å‡§õ ‡§î‡§∞?", "‡§π‡§æ‡§Å ‡§¨‡§§‡§æ‡§á‡§è‡•§"]
        prompt_index = (call_state.interaction_count - 1) % len(quick_prompts) if call_state else 0
        
        gather.say(quick_prompts[prompt_index], voice="Polly.Aditi", language="hi-IN")
        response.append(gather)
        
        # Quick ending
        response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", voice="Polly.Aditi", language="hi-IN")
        
        return Response(str(response), content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in process_voice: {e}")
        response = VoiceResponse()
        response.say("‡§è‡§ï ‡§∏‡•á‡§ï‡§Ç‡§°, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§", voice="Polly.Aditi", language="hi-IN")
        response.hangup()
        return Response(str(response), content_type='text/xml')

# Add a real-time speech processing endpoint
@app.route("/speech_update", methods=['POST'])
def speech_update():
    """Handle real-time speech updates for interruption detection"""
    try:
        caller_id = request.form.get('From', 'unknown')
        partial_speech = request.form.get('PartialSpeechResult', '')
        
        if partial_speech and len(partial_speech) > 5:
            # Detect interruption intent in real-time
            if detect_interruption_intent(partial_speech):
                logger.info(f"Interruption detected from {caller_id}: {partial_speech}")
                
                # Mark as interrupted
                call_state = call_states.get(caller_id)
                if call_state:
                    call_state.interruption_count += 1
                    call_state.rapid_interruptions += 1
        
        return Response('', content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in speech_update: {e}")
        return Response('', content_type='text/xml')

@app.route("/", methods=['GET'])
def home():
    active_calls = len([state for state in call_states.values() 
                       if datetime.now() - state.last_activity < timedelta(minutes=2)])
    
    total_interruptions = sum(state.interruption_count for state in call_states.values())
    
    return f"""
    <h1>‚ö° Lightning Fast Voice Bot</h1>
    <p><strong>Status:</strong> ‚úÖ Hyper-Responsive & Active</p>
    <p><strong>Groq API:</strong> {'‚ö° Ultra-Fast' if client else '‚ùå Disconnected'}</p>
    <p><strong>Response Time:</strong> <1 second</p>
    <p><strong>Active Calls:</strong> {active_calls}</p>
    <p><strong>Total Conversations:</strong> {len(conversation_contexts)}</p>
    <p><strong>Interruptions Handled:</strong> {total_interruptions}</p>
    
    <h3>‚ö° Speed Features:</h3>
    <ul>
        <li>‚úÖ Real-time interruption detection</li>
        <li>‚úÖ Sub-second response time</li>
        <li>‚úÖ Quick speech recognition</li>
        <li>‚úÖ Minimal latency processing</li>
        <li>‚úÖ Instant conversation flow</li>
        <li>‚úÖ Smart timeout management</li>
    </ul>
    
    <p><strong>Optimizations:</strong></p>
    <ul>
        <li>üöÄ Reduced token limits for speed</li>
        <li>üöÄ Aggressive memory management</li>
        <li>üöÄ Quick sentiment analysis</li>
        <li>üöÄ Minimal processing overhead</li>
    </ul>
    """

@app.route("/test_speed", methods=['GET'])
def test_speed():
    """Test response speed"""
    try:
        start_time = time.time()
        test_response = generate_fast_response("‡§π‡•à‡§≤‡•ã, ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç ‡§Ü‡§™?", "speed_test")
        end_time = time.time()
        
        response_time = round((end_time - start_time) * 1000, 2)  # milliseconds
        
        return f"""
        <h2>‚ö° Speed Test Results</h2>
        <p><strong>Test Query:</strong> ‡§π‡•à‡§≤‡•ã, ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç ‡§Ü‡§™?</p>
        <p><strong>Response:</strong> {test_response}</p>
        <p><strong>Response Time:</strong> {response_time} ms</p>
        <p><strong>Status:</strong> {'üöÄ LIGHTNING FAST' if response_time < 1000 else '‚ö†Ô∏è NEEDS OPTIMIZATION'}</p>
        """
    except Exception as e:
        return f"<h2>‚ùå Speed Test Failed</h2><p>{str(e)}</p>"

@app.route("/interruption_stats", methods=['GET'])
def interruption_stats():
    """Show interruption handling statistics"""
    try:
        total_interruptions = sum(state.interruption_count for state in call_states.values())
        rapid_interruptions = sum(state.rapid_interruptions for state in call_states.values())
        
        return f"""
        <h2>üîÑ Interruption Handling Stats</h2>
        <p><strong>Total Interruptions Handled:</strong> {total_interruptions}</p>
        <p><strong>Rapid Interruptions:</strong> {rapid_interruptions}</p>
        <p><strong>Active Call States:</strong> {len(call_states)}</p>
        
        <h3>Per-Call Stats:</h3>
        <ul>
        {''.join([f"<li><strong>{state.caller_id}:</strong> {state.interruption_count} interruptions</li>" 
                 for state in call_states.values()])}
        </ul>
        """
    except Exception as e:
        return f"<h2>‚ùå Stats Error</h2><p>{str(e)}</p>"

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    
    print("‚ö° Starting LIGHTNING FAST Voice Bot...")
    print(f"üöÄ Groq API: {'Ready for Speed' if GROQ_API_KEY else 'Missing'}")
    print(f"‚ö° Twilio: {'Optimized' if TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN else 'Missing'}")
    print(f"üåê Port: {port}")
    print("üî• Features: Real-time interruptions, <1s response, Ultra-fast processing")
    
    app.run(debug=debug_mode, host='0.0.0.0', port=port, threaded=True)
