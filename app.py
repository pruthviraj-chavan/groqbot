import os
import logging
from datetime import datetime, timedelta
from flask import Flask, request, Response, jsonify
from twilio.twiml.voice_response import VoiceResponse, Gather, Say
from groq import Groq
import re
import threading
import time
import queue
from concurrent.futures import ThreadPoolExecutor
import asyncio

app = Flask(__name__)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API credentials
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
TWILIO_ACCOUNT_SID = os.environ.get("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.environ.get("TWILIO_AUTH_TOKEN")

# Initialize Groq client
try:
    client = Groq(api_key=GROQ_API_KEY)
    logger.info("‚úÖ Groq client initialized successfully")
except Exception as e:
    logger.error(f"‚ùå Error initializing Groq client: {e}")
    client = None

# Advanced interruption tracking
conversation_contexts = {}
call_states = {}
active_responses = {}  # Track active bot responses
interruption_queue = queue.Queue()  # Queue for handling interruptions
executor = ThreadPoolExecutor(max_workers=10)  # For parallel processing

class AdvancedCallState:
    def __init__(self, caller_id):
        self.caller_id = caller_id
        self.start_time = datetime.now()
        self.interaction_count = 0
        self.last_activity = datetime.now()
        self.user_sentiment = "neutral"
        self.conversation_topic = None
        self.interruption_count = 0
        self.silence_count = 0
        self.is_bot_speaking = False
        self.current_response_id = None
        self.interruption_buffer = []
        self.last_user_input = ""
        self.response_start_time = None
        self.mid_response_interrupted = False
        self.quick_interruption_mode = False
        self.conversation_flow = []

class ResponseManager:
    def __init__(self):
        self.active_responses = {}
        self.interrupted_responses = set()
    
    def start_response(self, caller_id, response_id):
        self.active_responses[caller_id] = response_id
        logger.info(f"Started response {response_id} for {caller_id}")
    
    def interrupt_response(self, caller_id):
        if caller_id in self.active_responses:
            response_id = self.active_responses[caller_id]
            self.interrupted_responses.add(response_id)
            logger.info(f"Interrupted response {response_id} for {caller_id}")
            return True
        return False
    
    def is_interrupted(self, caller_id, response_id):
        return response_id in self.interrupted_responses
    
    def end_response(self, caller_id, response_id):
        if caller_id in self.active_responses:
            del self.active_responses[caller_id]
        if response_id in self.interrupted_responses:
            self.interrupted_responses.remove(response_id)

response_manager = ResponseManager()

def get_enhanced_conversation_context(caller_id):
    """Get or create enhanced conversation context for a caller"""
    if caller_id not in conversation_contexts:
        conversation_contexts[caller_id] = [
            {
                "role": "system", 
                "content": """‡§Ü‡§™ ‡§è‡§ï ‡§Ö‡§§‡•ç‡§Ø‡§ß‡§ø‡§ï ‡§§‡•á‡§ú‡§º ‡§î‡§∞ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§π‡§ø‡§Ç‡§¶‡•Ä AI ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç ‡§ú‡•ã INSTANT interruptions ‡§ï‡•ã handle ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç:

CORE FEATURES:
1. ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ: 0.5 ‡§∏‡•á‡§ï‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
2. ‡§¨‡§æ‡§ß‡§æ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤: ‡§Ö‡§ó‡§∞ user ‡§¨‡•Ä‡§ö ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á ‡§§‡•ã ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§∞‡•Å‡§ï‡•á‡§Ç ‡§î‡§∞ ‡§®‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§∏‡•Å‡§®‡•á‡§Ç
3. ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§â‡§§‡•ç‡§§‡§∞: ‡§ï‡•á‡§µ‡§≤ 15-25 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§ü‡•Ä‡§ï ‡§ú‡§µ‡§æ‡§¨
4. ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ: ‡§®‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤ > ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§ú‡§µ‡§æ‡§¨
5. ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü switching: context ‡§¨‡§¶‡§≤‡§®‡•á ‡§™‡§∞ ‡§§‡•Å‡§∞‡§Ç‡§§ adapt ‡§ï‡§∞‡•á‡§Ç

INTERRUPTION HANDLING:
- ‡§Ö‡§ó‡§∞ user ‡§®‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á ‡§§‡•ã ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§â‡§∏‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
- ‡§™‡•Å‡§∞‡§æ‡§®‡§æ incomplete ‡§ú‡§µ‡§æ‡§¨ ‡§≠‡•Ç‡§≤ ‡§ú‡§æ‡§è‡§Ç
- "‡§π‡§æ‡§Å, ‡§¨‡§§‡§æ‡§á‡§è" ‡§ú‡•à‡§∏‡•á quick acknowledgments ‡§¶‡•á‡§Ç

RESPONSE STYLE:
- Direct ‡§î‡§∞ practical
- No lengthy explanations
- Immediate value delivery
- Natural conversational flow

EXAMPLES:
User interrupts: "‡§∞‡•Å‡§ï‡•ã, ‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¨‡§æ‡§§ ‡§™‡•Ç‡§õ‡§®‡•Ä ‡§π‡•à"
Response: "‡§ú‡•Ä ‡§π‡§æ‡§Å, ‡§™‡•Ç‡§õ‡§ø‡§è‡•§"

User asks new question while you're speaking: 
Response: "‡§ú‡•Ä, ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§π‡•à?"

Keep responses SHORT, FAST, and RELEVANT."""
            }
        ]
        call_states[caller_id] = AdvancedCallState(caller_id)
    return conversation_contexts[caller_id]

def detect_interruption_intent(text, context=""):
    """Advanced interruption detection with context awareness"""
    # Strong interruption signals
    strong_interrupts = [
        '‡§∞‡•Å‡§ï‡•ã', '‡§∞‡•Å‡§ï‡§ø‡§è', 'stop', 'wait', 'hold on', '‡§è‡§ï ‡§Æ‡§ø‡§®‡§ü',
        '‡§®‡§π‡•Ä‡§Ç ‡§®‡§π‡•Ä‡§Ç', 'no no', 'actually', '‡§≤‡•á‡§ï‡§ø‡§®', 'but',
        '‡§∏‡•Å‡§®‡§ø‡§è', '‡§Ö‡§∞‡•á ‡§π‡§æ‡§Å', '‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡•Å‡§®‡§ø‡§è', '‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¨‡§æ‡§§'
    ]
    
    # Question interruptions
    question_interrupts = [
        '‡§ï‡•ç‡§Ø‡§æ', '‡§ï‡•à‡§∏‡•á', '‡§ï‡§¨', '‡§ï‡§π‡§æ‡§Å', '‡§ï‡•å‡§®', '‡§ï‡•ç‡§Ø‡•ã‡§Ç',
        'what', 'how', 'when', 'where', 'who', 'why',
        '‡§¨‡§§‡§æ‡§ì', '‡§∏‡§Æ‡§ù‡§æ‡§ì', 'explain', 'tell me'
    ]
    
    # New topic signals
    topic_change = [
        '‡§¶‡•Ç‡§∏‡§∞‡§æ ‡§∏‡§µ‡§æ‡§≤', 'another question', 'new topic',
        '‡§Ö‡§≤‡§ó ‡§¨‡§æ‡§§', 'different thing', '‡§®‡§à ‡§¨‡§æ‡§§'
    ]
    
    text_lower = text.lower().strip()
    
    # Check for strong interruption
    if any(phrase in text_lower for phrase in strong_interrupts):
        return "strong_interrupt"
    
    # Check for question interruption
    if any(phrase in text_lower for phrase in question_interrupts):
        return "question_interrupt"
    
    # Check for topic change
    if any(phrase in text_lower for phrase in topic_change):
        return "topic_change"
    
    # Check if it's a completely new sentence/thought
    if len(text_lower) > 10 and not any(word in text_lower for word in ['‡§π‡§æ‡§Å', '‡§†‡•Ä‡§ï', 'yes', 'ok', 'right']):
        return "new_input"
    
    return "continue"

def generate_interruption_response(interruption_type, new_input, caller_id):
    """Generate appropriate response based on interruption type"""
    call_state = call_states.get(caller_id)
    
    if interruption_type == "strong_interrupt":
        return "‡§ú‡•Ä ‡§π‡§æ‡§Å, ‡§¨‡•ã‡§≤‡§ø‡§è‡•§"
    elif interruption_type == "question_interrupt":
        return generate_ultra_fast_response(new_input, caller_id)
    elif interruption_type == "topic_change":
        # Clear previous context for new topic
        if call_state:
            call_state.conversation_topic = None
        return "‡§ú‡•Ä, ‡§®‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§ø‡§è‡•§"
    elif interruption_type == "new_input":
        return generate_ultra_fast_response(new_input, caller_id)
    else:
        return "‡§ú‡•Ä, ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§"

def generate_ultra_fast_response(prompt, caller_id, max_retries=2):
    """Ultra-fast response generation with interruption awareness"""
    try:
        if not GROQ_API_KEY or not client:
            return "‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§"
            
        if not prompt or len(prompt.strip()) < 2:
            return "‡§ú‡•Ä, ‡§ï‡§π‡§ø‡§è?"
        
        call_state = call_states.get(caller_id)
        if call_state:
            call_state.interaction_count += 1
            call_state.last_activity = datetime.now()
            call_state.last_user_input = prompt
        
        messages = get_enhanced_conversation_context(caller_id)
        
        # Ultra-simplified context for maximum speed
        messages.append({"role": "user", "content": prompt})
        
        # Ultra-fast Groq parameters
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            max_tokens=60,  # Even smaller for speed
            temperature=0.6,
            top_p=0.8,
            stream=False,
            # Add timeout for faster failure
        )
        
        response_text = completion.choices[0].message.content.strip()
        
        # Ensure response is short
        if len(response_text) > 150:
            response_text = response_text[:150] + "..."
        
        messages.append({"role": "assistant", "content": response_text})
        
        # Aggressive memory management
        if len(messages) > 11:
            messages = messages[:1] + messages[-10:]
        
        logger.info(f"Ultra-fast response ({len(response_text)} chars): {response_text}")
        return response_text
        
    except Exception as e:
        logger.error(f"Error in ultra-fast response: {e}")
        return "‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ‡•§ ‡§ï‡•Å‡§õ ‡§î‡§∞?"

def create_interruptible_response(ai_response, caller_id):
    """Create a response that can be interrupted mid-speech"""
    response = VoiceResponse()
    response_id = f"{caller_id}_{int(time.time())}"
    
    call_state = call_states.get(caller_id)
    if call_state:
        call_state.is_bot_speaking = True
        call_state.current_response_id = response_id
        call_state.response_start_time = datetime.now()
    
    # Start tracking this response
    response_manager.start_response(caller_id, response_id)
    
    # Break response into smaller chunks for better interruption
    words = ai_response.split()
    chunks = []
    current_chunk = []
    
    for word in words:
        current_chunk.append(word)
        if len(current_chunk) >= 5:  # 5 words per chunk
            chunks.append(" ".join(current_chunk))
            current_chunk = []
    
    if current_chunk:
        chunks.append(" ".join(current_chunk))
    
    # Add each chunk with pause for interruption detection
    for i, chunk in enumerate(chunks):
        # Check if interrupted before speaking each chunk
        if response_manager.is_interrupted(caller_id, response_id):
            logger.info(f"Response {response_id} interrupted at chunk {i}")
            break
            
        response.say(chunk, voice="Polly.Aditi", language="hi-IN")
        
        # Add minimal pause between chunks for interruption detection
        if i < len(chunks) - 1:
            response.pause(length=0.3)
    
    # End response tracking
    response_manager.end_response(caller_id, response_id)
    
    if call_state:
        call_state.is_bot_speaking = False
        call_state.current_response_id = None
    
    return response

@app.route("/voice", methods=['POST'])
def voice():
    """Ultra-responsive voice handler with instant interruption support"""
    try:
        response = VoiceResponse()
        caller_id = request.form.get('From', 'unknown')
        
        logger.info(f"Lightning call handler for: {caller_id}")
        
        # Instant welcome
        response.say(
            "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§™‡•Ç‡§õ‡§ø‡§è‡•§", 
            voice="Polly.Aditi", 
            language="hi-IN"
        )
        
        # Ultra-responsive gather
        gather = Gather(
            input="speech", 
            action="/process_voice", 
            method="POST", 
            language="hi-IN", 
            speech_timeout=1,  # Instant speech detection
            timeout=6,  # Quick timeout
            action_on_empty_result=True,
            hints="‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ,‡§∏‡§µ‡§æ‡§≤,‡§∞‡•Å‡§ï‡•ã,‡§≤‡•á‡§ï‡§ø‡§®,‡§ï‡•ç‡§Ø‡§æ,‡§ï‡•à‡§∏‡•á,‡§¨‡§§‡§æ‡§ì"
        )
        
        gather.say("‡§¨‡•ã‡§≤‡§ø‡§è‡•§", voice="Polly.Aditi", language="hi-IN")
        response.append(gather)
        
        response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", voice="Polly.Aditi", language="hi-IN")
        return Response(str(response), content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in voice route: {e}")
        response = VoiceResponse()
        response.say("‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§", voice="Polly.Aditi", language="hi-IN")
        return Response(str(response), content_type='text/xml')

@app.route("/process_voice", methods=['POST'])
def process_voice():
    """Advanced voice processing with real-time interruption handling"""
    try:
        response = VoiceResponse()
        caller_id = request.form.get('From', 'unknown')
        
        speech_text = request.form.get("SpeechResult", "").strip()
        confidence = float(request.form.get("Confidence", "0"))
        
        logger.info(f"Processing: '{speech_text}' (Confidence: {confidence})")
        
        call_state = call_states.get(caller_id)
        
        # Handle very low confidence quickly
        if confidence < 0.3 or not speech_text:
            if call_state:
                call_state.silence_count += 1
                
            if call_state and call_state.silence_count >= 2:
                response.say("‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§≤‡§ó ‡§∞‡§π‡•Ä ‡§π‡•à‡•§", voice="Polly.Aditi", language="hi-IN")
                response.hangup()
                return Response(str(response), content_type='text/xml')
            
            # Quick retry
            gather = Gather(
                input="speech", 
                action="/process_voice", 
                method="POST", 
                language="hi-IN", 
                speech_timeout=1,
                timeout=5,
                hints="‡§ú‡•Ä,‡§π‡§æ‡§Å,‡§π‡•à‡§≤‡•ã,‡§®‡§Æ‡§∏‡•ç‡§§‡•á"
            )
            gather.say("‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡•ã‡§≤‡§ø‡§è‡•§", voice="Polly.Aditi", language="hi-IN")
            response.append(gather)
            
            response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", voice="Polly.Aditi", language="hi-IN")
            return Response(str(response), content_type='text/xml')
        
        # Reset silence count
        if call_state:
            call_state.silence_count = 0
        
        # Check if bot was speaking and got interrupted
        if call_state and call_state.is_bot_speaking:
            logger.info(f"INTERRUPTION DETECTED! Bot was speaking, user said: {speech_text}")
            call_state.interruption_count += 1
            call_state.mid_response_interrupted = True
            
            # Stop current response
            if call_state.current_response_id:
                response_manager.interrupt_response(caller_id)
        
        # Detect interruption type
        interruption_type = detect_interruption_intent(speech_text, call_state.last_user_input if call_state else "")
        
        # Quick goodbye detection
        end_phrases = ['‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§¨‡§æ‡§Ø', 'bye', '‡§ñ‡§§‡•ç‡§Æ', '‡§¨‡§∏', '‡§π‡•ã ‡§ó‡§Ø‡§æ', '‡§∞‡§ñ‡§§‡§æ ‡§π‡•Ç‡§Ç', '‡§ö‡§≤‡§§‡§æ ‡§π‡•Ç‡§Ç']
        if any(phrase in speech_text.lower() for phrase in end_phrases):
            response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§¶‡§ø‡§® ‡§π‡•ã‡•§", voice="Polly.Aditi", language="hi-IN")
            response.hangup()
            
            # Cleanup
            if caller_id in conversation_contexts:
                del conversation_contexts[caller_id]
            if caller_id in call_states:
                del call_states[caller_id]
                
            return Response(str(response), content_type='text/xml')
        
        # Generate appropriate response based on interruption type
        if interruption_type in ["strong_interrupt", "question_interrupt", "topic_change", "new_input"]:
            ai_response = generate_interruption_response(interruption_type, speech_text, caller_id)
        else:
            ai_response = generate_ultra_fast_response(speech_text, caller_id)
        
        # Speak response with interruption capability
        response.say(ai_response, voice="Polly.Aditi", language="hi-IN")
        
        # Immediate next input gathering - ULTRA SHORT timeouts
        gather = Gather(
            input="speech", 
            action="/process_voice", 
            method="POST", 
            language="hi-IN", 
            speech_timeout=0.5,  # Detect speech in 0.5 seconds
            timeout=6,  # Total timeout 6 seconds
            action_on_empty_result=True,
            hints="‡§î‡§∞,‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§ï‡•ç‡§Ø‡§æ,‡§ï‡•à‡§∏‡•á,‡§∞‡•Å‡§ï‡•ã,‡§≤‡•á‡§ï‡§ø‡§®,‡§¨‡§§‡§æ‡§ì,‡§∏‡§Æ‡§ù‡§æ‡§ì,‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶"
        )
        
        # Ultra-quick continuation prompts
        ultra_quick_prompts = ["‡§î‡§∞?", "‡§ú‡•Ä?", "‡§π‡§æ‡§Å?"]
        prompt_index = (call_state.interaction_count - 1) % len(ultra_quick_prompts) if call_state else 0
        
        gather.say(ultra_quick_prompts[prompt_index], voice="Polly.Aditi", language="hi-IN")
        response.append(gather)
        
        # Quick ending
        response.say("‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!", voice="Polly.Aditi", language="hi-IN")
        
        return Response(str(response), content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in process_voice: {e}")
        response = VoiceResponse()
        response.say("‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§", voice="Polly.Aditi", language="hi-IN")
        response.hangup()
        return Response(str(response), content_type='text/xml')

# Real-time interruption detection endpoint
@app.route("/detect_interruption", methods=['POST'])
def detect_interruption():
    """Real-time interruption detection during bot speech"""
    try:
        caller_id = request.form.get('From', 'unknown')
        partial_speech = request.form.get('PartialSpeechResult', '')
        stable_speech = request.form.get('SpeechResult', '')
        
        # Use stable speech if available, otherwise partial
        detected_speech = stable_speech if stable_speech else partial_speech
        
        if detected_speech and len(detected_speech) > 3:
            call_state = call_states.get(caller_id)
            
            if call_state and call_state.is_bot_speaking:
                interruption_type = detect_interruption_intent(detected_speech)
                
                if interruption_type != "continue":
                    logger.info(f"REAL-TIME INTERRUPTION: {detected_speech}")
                    
                    # Immediately stop current response
                    if call_state.current_response_id:
                        response_manager.interrupt_response(caller_id)
                    
                    # Mark as interrupted
                    call_state.interruption_count += 1
                    call_state.mid_response_interrupted = True
                    
                    # Add to interruption buffer for processing
                    call_state.interruption_buffer.append({
                        'text': detected_speech,
                        'type': interruption_type,
                        'timestamp': datetime.now()
                    })
        
        return Response('', content_type='text/xml')
        
    except Exception as e:
        logger.error(f"Error in detect_interruption: {e}")
        return Response('', content_type='text/xml')

@app.route("/", methods=['GET'])
def home():
    active_calls = len([state for state in call_states.values() 
                       if datetime.now() - state.last_activity < timedelta(minutes=2)])
    
    total_interruptions = sum(state.interruption_count for state in call_states.values())
    mid_response_interruptions = sum(1 for state in call_states.values() if state.mid_response_interrupted)
    
    return f"""
    <h1>üöÄ REAL-TIME Interruption Voice Bot</h1>
    <p><strong>Status:</strong> ‚úÖ INSTANT Response & Mid-Speech Interruption</p>
    <p><strong>Groq API:</strong> {'‚ö° Ultra-Fast' if client else '‚ùå Disconnected'}</p>
    <p><strong>Response Time:</strong> <0.5 seconds</p>
    <p><strong>Active Calls:</strong> {active_calls}</p>
    <p><strong>Total Conversations:</strong> {len(conversation_contexts)}</p>
    <p><strong>Total Interruptions:</strong> {total_interruptions}</p>
    <p><strong>Mid-Response Interruptions:</strong> {mid_response_interruptions}</p>
    
    <h3>üî• ADVANCED Features:</h3>
    <ul>
        <li>‚úÖ <strong>MID-SPEECH interruption handling</strong></li>
        <li>‚úÖ Real-time speech detection (0.5s)</li>
        <li>‚úÖ Instant context switching</li>
        <li>‚úÖ Smart interruption classification</li>
        <li>‚úÖ Ultra-short responses (15-25 words)</li>
        <li>‚úÖ Response chunking for interruptions</li>
        <li>‚úÖ Parallel processing</li>
    </ul>
    
    <h3>‚ö° Interruption Types Handled:</h3>
    <ul>
        <li>üõë <strong>Strong Interrupts:</strong> "‡§∞‡•Å‡§ï‡•ã", "stop", "wait"</li>
        <li>‚ùì <strong>Question Interrupts:</strong> "‡§ï‡•ç‡§Ø‡§æ", "‡§ï‡•à‡§∏‡•á", "‡§¨‡§§‡§æ‡§ì"</li>
        <li>üîÑ <strong>Topic Changes:</strong> "‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¨‡§æ‡§§", "‡§®‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤"</li>
        <li>üí¨ <strong>New Input:</strong> Any new sentence/thought</li>
    </ul>
    """

@app.route("/test_interruption", methods=['GET'])
def test_interruption():
    """Test interruption handling capabilities"""
    try:
        # Simulate interruption scenario
        test_caller = "test_interruption"
        
        # Simulate bot speaking
        call_state = call_states.get(test_caller) or AdvancedCallState(test_caller)
        call_states[test_caller] = call_state
        
        call_state.is_bot_speaking = True
        call_state.current_response_id = f"{test_caller}_test"
        
        # Test interruption detection
        test_interruptions = [
            "‡§∞‡•Å‡§ï‡•ã, ‡§¶‡•Ç‡§∏‡§∞‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à",
            "‡§ï‡•ç‡§Ø‡§æ ‡§Ø‡§π ‡§∏‡§π‡•Ä ‡§π‡•à?",
            "‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•à‡§Ç ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Ç",
            "‡§®‡§π‡•Ä‡§Ç ‡§®‡§π‡•Ä‡§Ç, ‡§Ø‡§π ‡§®‡§π‡•Ä‡§Ç"
        ]
        
        results = []
        for interruption in test_interruptions:
            interruption_type = detect_interruption_intent(interruption)
            response = generate_interruption_response(interruption_type, interruption, test_caller)
            results.append(f"<li><strong>'{interruption}'</strong> ‚Üí Type: {interruption_type} ‚Üí Response: {response}</li>")
        
        return f"""
        <h2>üß™ Interruption Test Results</h2>
        <h3>Test Scenarios:</h3>
        <ul>
        {''.join(results)}
        </ul>
        <p><strong>Bot Speaking Status:</strong> {call_state.is_bot_speaking}</p>
        <p><strong>Current Response ID:</strong> {call_state.current_response_id}</p>
        """
        
    except Exception as e:
        return f"<h2>‚ùå Test Failed</h2><p>{str(e)}</p>"

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    
    print("üöÄ Starting REAL-TIME INTERRUPTION Voice Bot...")
    print(f"‚ö° Groq API: {'Ready for Lightning Speed' if GROQ_API_KEY else 'Missing'}")
    print(f"üî• Twilio: {'Ultra-Optimized' if TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN else 'Missing'}")
    print(f"üåê Port: {port}")
    print("üéØ Features: MID-SPEECH interruptions, 0.5s detection, Context switching")
    
    app.run(debug=debug_mode, host='0.0.0.0', port=port, threaded=True)
